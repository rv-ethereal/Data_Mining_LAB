<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Enterprise Data Lake Platform</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 60px 40px;
            text-align: center;
            position: relative;
            overflow: hidden;
        }
        
        header::before {
            content: '';
            position: absolute;
            top: -50%;
            right: -50%;
            width: 200%;
            height: 200%;
            background: radial-gradient(circle, rgba(255,255,255,0.1) 1px, transparent 1px);
            background-size: 50px 50px;
            animation: moveBackground 20s linear infinite;
        }
        
        @keyframes moveBackground {
            0% { transform: translate(0, 0); }
            100% { transform: translate(50px, 50px); }
        }
        
        header h1 {
            font-size: 3.5em;
            margin-bottom: 10px;
            position: relative;
            z-index: 1;
            text-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);
        }
        
        header p {
            font-size: 1.3em;
            opacity: 0.95;
            position: relative;
            z-index: 1;
        }
        
        .badge {
            display: inline-block;
            background: rgba(255, 255, 255, 0.2);
            color: white;
            padding: 8px 16px;
            border-radius: 25px;
            font-size: 0.9em;
            margin: 5px;
            margin-top: 20px;
            position: relative;
            z-index: 1;
        }
        
        main {
            padding: 60px 40px;
        }
        
        section {
            margin-bottom: 60px;
        }
        
        h2 {
            color: #667eea;
            font-size: 2.2em;
            margin-bottom: 30px;
            padding-bottom: 15px;
            border-bottom: 3px solid #667eea;
            display: inline-block;
        }
        
        h3 {
            color: #764ba2;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 15px;
        }
        
        .features-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 30px;
            margin: 30px 0;
        }
        
        .feature-card {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 30px;
            border-radius: 10px;
            transition: transform 0.3s, box-shadow 0.3s;
            border-left: 5px solid #667eea;
        }
        
        .feature-card:hover {
            transform: translateY(-10px);
            box-shadow: 0 15px 35px rgba(102, 126, 234, 0.2);
        }
        
        .feature-card h4 {
            color: #667eea;
            font-size: 1.3em;
            margin-bottom: 15px;
        }
        
        .feature-card p {
            color: #555;
            line-height: 1.8;
        }
        
        .architecture-section {
            background: #f8f9fa;
            padding: 40px;
            border-radius: 10px;
            margin: 30px 0;
        }
        
        .pipeline-flow {
            display: flex;
            align-items: center;
            justify-content: space-around;
            margin: 40px 0;
            flex-wrap: wrap;
            gap: 20px;
        }
        
        .pipeline-stage {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 10px;
            text-align: center;
            flex: 1;
            min-width: 150px;
            position: relative;
            box-shadow: 0 10px 25px rgba(102, 126, 234, 0.2);
        }
        
        .pipeline-stage::after {
            content: '‚Üí';
            position: absolute;
            right: -40px;
            font-size: 2em;
            color: #667eea;
        }
        
        .pipeline-stage:last-child::after {
            content: '';
        }
        
        .code-block {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 20px 0;
            font-family: 'Courier New', monospace;
            border-left: 4px solid #667eea;
        }
        
        .code-block code {
            font-size: 0.95em;
            line-height: 1.5;
        }
        
        .installation-steps {
            background: #e8f4f8;
            padding: 30px;
            border-radius: 10px;
            margin: 20px 0;
            border-left: 5px solid #00bcd4;
        }
        
        .installation-steps ol {
            margin-left: 20px;
            list-style-position: inside;
        }
        
        .installation-steps li {
            margin: 15px 0;
            padding-left: 10px;
        }
        
        .stats-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 30px;
            border-radius: 10px;
            text-align: center;
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.1);
        }
        
        .stat-card .number {
            font-size: 2.5em;
            font-weight: bold;
            margin-bottom: 10px;
        }
        
        .stat-card .label {
            font-size: 1em;
            opacity: 0.9;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background: white;
            border-radius: 8px;
            overflow: hidden;
            box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
        }
        
        th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            text-align: left;
            font-weight: 600;
        }
        
        td {
            padding: 12px 15px;
            border-bottom: 1px solid #eee;
        }
        
        tr:hover {
            background: #f5f5f5;
        }
        
        .tech-stack {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .tech-item {
            background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
            padding: 20px;
            border-radius: 8px;
            text-align: center;
            border: 2px solid #667eea;
        }
        
        .tech-item strong {
            color: #667eea;
            display: block;
            margin-bottom: 8px;
        }
        
        .contact-section {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 50px 40px;
            border-radius: 10px;
            text-align: center;
            margin-top: 60px;
        }
        
        .contact-section h2 {
            border-bottom-color: white;
            color: white;
        }
        
        .contact-section p {
            font-size: 1.1em;
            margin: 15px 0;
            opacity: 0.95;
        }
        
        footer {
            background: #2d3748;
            color: white;
            text-align: center;
            padding: 30px;
            margin-top: 60px;
        }
        
        .alert {
            padding: 20px;
            margin: 20px 0;
            border-radius: 8px;
            border-left: 5px solid;
        }
        
        .alert-info {
            background: #e3f2fd;
            border-left-color: #2196f3;
            color: #1565c0;
        }
        
        .alert-warning {
            background: #fff3e0;
            border-left-color: #ff9800;
            color: #e65100;
        }
        
        .alert-success {
            background: #e8f5e9;
            border-left-color: #4caf50;
            color: #2e7d32;
        }
        
        @media (max-width: 768px) {
            header h1 {
                font-size: 2em;
            }
            
            .pipeline-flow {
                flex-direction: column;
            }
            
            .pipeline-stage::after {
                right: auto;
                bottom: -40px;
                content: '‚Üì';
            }
            
            main {
                padding: 30px 20px;
            }
            
            .features-grid {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üöÄ Enterprise Data Lake Platform</h1>
            <p>Advanced ETL & Analytics Infrastructure</p>
            <div>
                <span class="badge">üî• Production Ready</span>
                <span class="badge">‚ö° High Performance</span>
                <span class="badge">üõ°Ô∏è Enterprise Grade</span>
                <span class="badge">üîÑ Automated Orchestration</span>
            </div>
        </header>
        
        <main>
            <!-- Overview Section -->
            <section>
                <h2>üìã Overview</h2>
                <p style="font-size: 1.1em; color: #555; margin: 20px 0;">
                    A comprehensive, enterprise-grade data lake platform built with Apache Spark, Airflow, and Superset. 
                    This solution provides end-to-end data processing, orchestration, and visualization capabilities for 
                    modern data-driven organizations.
                </p>
                
                <div class="alert alert-info">
                    <strong>‚úì Key Capability:</strong> Process millions of records in parallel with fault-tolerant distributed computing
                </div>
            </section>
            
            <!-- Quick Stats -->
            <section>
                <h2>üìä Platform Metrics</h2>
                <div class="stats-grid">
                    <div class="stat-card">
                        <div class="number">6+</div>
                        <div class="label">Analytical Tables</div>
                    </div>
                    <div class="stat-card">
                        <div class="number">3</div>
                        <div class="label">Data Layers</div>
                    </div>
                    <div class="stat-card">
                        <div class="number">100%</div>
                        <div class="label">Automated</div>
                    </div>
                    <div class="stat-card">
                        <div class="number">24/7</div>
                        <div class="label">Monitoring</div>
                    </div>
                </div>
            </section>
            
            <!-- Architecture Section -->
            <section>
                <h2>üèóÔ∏è Architecture</h2>
                <div class="architecture-section">
                    <h3>Data Processing Pipeline</h3>
                    <div class="pipeline-flow">
                        <div class="pipeline-stage">
                            <strong>üì• Ingestion</strong>
                            <p style="font-size: 0.9em; margin-top: 10px;">Raw Data Sources</p>
                        </div>
                        <div class="pipeline-stage">
                            <strong>‚öôÔ∏è Processing</strong>
                            <p style="font-size: 0.9em; margin-top: 10px;">Spark ETL</p>
                        </div>
                        <div class="pipeline-stage">
                            <strong>üíæ Storage</strong>
                            <p style="font-size: 0.9em; margin-top: 10px;">Parquet Format</p>
                        </div>
                        <div class="pipeline-stage">
                            <strong>üìà Analytics</strong>
                            <p style="font-size: 0.9em; margin-top: 10px;">Superset BI</p>
                        </div>
                    </div>
                </div>
                
                <h3>Directory Structure</h3>
                <div class="code-block"><code>onprem-datalake-msd24014/
‚îú‚îÄ‚îÄ spark/
‚îÇ   ‚îî‚îÄ‚îÄ spark_etl.py           # Enterprise ETL Pipeline
‚îú‚îÄ‚îÄ airflow/
‚îÇ   ‚îî‚îÄ‚îÄ dags/
‚îÇ       ‚îî‚îÄ‚îÄ spark_etl_dag.py   # Orchestration DAG
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îî‚îÄ‚îÄ parquet_to_sqlite.py   # Data Export Tool
‚îú‚îÄ‚îÄ datalake/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                   # Source data
‚îÇ   ‚îú‚îÄ‚îÄ processed/             # Cleansed data
‚îÇ   ‚îî‚îÄ‚îÄ warehouse/             # Analytics tables
‚îú‚îÄ‚îÄ app.py                     # Superset Application
‚îî‚îÄ‚îÄ requirements.txt           # Dependencies</code></div>
            </section>
            
            <!-- Features Section -->
            <section>
                <h2>‚ú® Core Features</h2>
                <div class="features-grid">
                    <div class="feature-card">
                        <h4>üîÑ Automated ETL</h4>
                        <p>Fully automated daily ETL pipeline with Airflow orchestration, handling data ingestion, transformation, and loading at scale.</p>
                    </div>
                    <div class="feature-card">
                        <h4>‚ö° Distributed Processing</h4>
                        <p>Apache Spark enables parallel processing of large datasets with automatic optimization and fault tolerance.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üìä Advanced Analytics</h4>
                        <p>Pre-built analytical tables for revenue analysis, customer segmentation, and temporal trends with drill-down capabilities.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üé® Interactive Dashboards</h4>
                        <p>Apache Superset provides intuitive data visualization and exploration with customizable dashboards and real-time updates.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üõ°Ô∏è Data Governance</h4>
                        <p>Multi-layer data architecture (raw, processed, warehouse) ensures data quality and compliance requirements.</p>
                    </div>
                    <div class="feature-card">
                        <h4>üîê Enterprise Security</h4>
                        <p>Built-in security controls with user authentication, role-based access, and audit logging capabilities.</p>
                    </div>
                </div>
            </section>
            
            <!-- Technology Stack -->
            <section>
                <h2>üõ†Ô∏è Technology Stack</h2>
                <div class="tech-stack">
                    <div class="tech-item">
                        <strong>Apache Spark</strong>
                        <small>v3.5+</small>
                    </div>
                    <div class="tech-item">
                        <strong>Apache Airflow</strong>
                        <small>v2.6.3</small>
                    </div>
                    <div class="tech-item">
                        <strong>Superset</strong>
                        <small>Latest</small>
                    </div>
                    <div class="tech-item">
                        <strong>Python</strong>
                        <small>3.10+</small>
                    </div>
                    <div class="tech-item">
                        <strong>Pandas</strong>
                        <small>v2.1+</small>
                    </div>
                    <div class="tech-item">
                        <strong>SQLite</strong>
                        <small>v3.0+</small>
                    </div>
                </div>
            </section>
            
            <!-- Installation Section -->
            <section>
                <h2>üöÄ Installation & Setup</h2>
                
                <h3>Prerequisites</h3>
                <ul style="margin-left: 20px; line-height: 2;">
                    <li>Python 3.10 or higher</li>
                    <li>Java 11+ (for Spark)</li>
                    <li>At least 8GB RAM</li>
                    <li>20GB free disk space</li>
                </ul>
                
                <h3>Step 1: Environment Setup</h3>
                <div class="installation-steps">
                    <ol>
                        <li><strong>Create virtual environment:</strong>
                            <div class="code-block"><code>python -m venv myeve</code></div>
                        </li>
                        <li><strong>Activate virtual environment:</strong>
                            <div class="code-block"><code># Windows
myeve\Scripts\activate

# Linux/Mac
source myeve/bin/activate</code></div>
                        </li>
                        <li><strong>Install dependencies:</strong>
                            <div class="code-block"><code>pip install -r requirements.txt</code></div>
                        </li>
                    </ol>
                </div>
                
                <h3>Step 2: Run ETL Pipeline</h3>
                <div class="code-block"><code>python spark/spark_etl.py</code></div>
                
                <h3>Step 3: Export to SQLite</h3>
                <div class="code-block"><code>python tools/parquet_to_sqlite.py</code></div>
                
                <h3>Step 4: Start Analytics Platform</h3>
                <div class="code-block"><code>python app.py</code></div>
                
                <div class="alert alert-success">
                    <strong>‚úì Setup Complete:</strong> Access Superset at http://localhost:8088
                </div>
            </section>
            
            <!-- Data Flows Section -->
            <section>
                <h2>üìä Analytical Tables</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Table Name</th>
                            <th>Description</th>
                            <th>Use Case</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>revenue_by_product</strong></td>
                            <td>Product-level revenue metrics with quantity and pricing analysis</td>
                            <td>Product performance dashboard</td>
                        </tr>
                        <tr>
                            <td><strong>revenue_by_region</strong></td>
                            <td>Geographic revenue distribution with regional performance indicators</td>
                            <td>Market expansion planning</td>
                        </tr>
                        <tr>
                            <td><strong>payment_analysis</strong></td>
                            <td>Payment method adoption and transaction volume analysis</td>
                            <td>Payment strategy optimization</td>
                        </tr>
                        <tr>
                            <td><strong>customer_summary</strong></td>
                            <td>Customer-level lifetime value and purchase behavior analysis</td>
                            <td>Customer segmentation & retention</td>
                        </tr>
                        <tr>
                            <td><strong>status_summary</strong></td>
                            <td>Order status distribution and fulfillment metrics</td>
                            <td>Operations monitoring</td>
                        </tr>
                        <tr>
                            <td><strong>monthly_sales</strong></td>
                            <td>Temporal sales trends for forecasting and planning</td>
                            <td>Seasonal analysis & forecasting</td>
                        </tr>
                    </tbody>
                </table>
            </section>
            
            <!-- Best Practices -->
            <section>
                <h2>üí° Best Practices</h2>
                <div class="features-grid">
                    <div class="feature-card">
                        <h4>Data Validation</h4>
                        <p>Always validate input data quality before processing. The pipeline includes built-in null checks and duplicate removal.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Schedule Management</h4>
                        <p>Configure Airflow DAG schedules based on data freshness requirements. Current setup runs daily at midnight.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Monitoring</h4>
                        <p>Monitor pipeline execution times, data quality metrics, and storage usage regularly for optimal performance.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Backups</h4>
                        <p>Implement regular backups of warehouse.db and configuration files. Consider cloud storage for disaster recovery.</p>
                    </div>
                </div>
            </section>
            
            <!-- Troubleshooting -->
            <section>
                <h2>üîß Troubleshooting</h2>
                
                <h3>Issue: Spark Out of Memory</h3>
                <div class="code-block"><code># Increase Spark memory allocation
export SPARK_LOCAL_IP=127.0.0.1
spark-submit --driver-memory 4G --executor-memory 4G spark/spark_etl.py</code></div>
                
                <h3>Issue: Parquet Files Not Found</h3>
                <div class="alert alert-warning">
                    Ensure ETL pipeline completes successfully before running the export tool. Check directory permissions.
                </div>
                
                <h3>Issue: Superset Connection Error</h3>
                <div class="code-block"><code># Verify database path
python tools/parquet_to_sqlite.py

# Check database creation
sqlite3 datalake/warehouse.db ".tables"</code></div>
            </section>
            
            <!-- Performance Metrics -->
            <section>
                <h2>‚ö° Performance Specifications</h2>
                <table>
                    <thead>
                        <tr>
                            <th>Operation</th>
                            <th>Typical Duration</th>
                            <th>Data Volume</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Data Ingestion</td>
                            <td>5-10 seconds</td>
                            <td>100K+ records</td>
                        </tr>
                        <tr>
                            <td>ETL Transformation</td>
                            <td>15-30 seconds</td>
                            <td>All data</td>
                        </tr>
                        <tr>
                            <td>Aggregations & Metrics</td>
                            <td>10-20 seconds</td>
                            <td>6 tables</td>
                        </tr>
                        <tr>
                            <td>Data Persistence</td>
                            <td>5-15 seconds</td>
                            <td>Parquet export</td>
                        </tr>
                        <tr>
                            <td>SQLite Export</td>
                            <td>10-20 seconds</td>
                            <td>All tables</td>
                        </tr>
                    </tbody>
                </table>
            </section>
            
            <!-- Integration Section -->
            <section>
                <h2>üîó Integration Points</h2>
                <div class="features-grid">
                    <div class="feature-card">
                        <h4>Data Sources</h4>
                        <p>CSV files in datalake/raw/. Easily extensible to support JSON, Parquet, and database sources.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Data Warehouses</h4>
                        <p>Parquet-based local warehouse. Compatible with cloud storage (S3, GCS, ADLS) with minimal configuration.</p>
                    </div>
                    <div class="feature-card">
                        <h4>BI Tools</h4>
                        <p>Native Superset integration. SQLite database compatible with Tableau, Power BI, and other visualization platforms.</p>
                    </div>
                    <div class="feature-card">
                        <h4>Orchestration</h4>
                        <p>Airflow-based workflow automation with REST API access for external scheduling and monitoring systems.</p>
                    </div>
                </div>
            </section>
            
            <!-- Documentation -->
            <section>
                <h2>üìö Module Documentation</h2>
                
                <h3>spark/spark_etl.py</h3>
                <p>Enterprise-grade ETL pipeline with class-based architecture. Handles data ingestion, cleansing, transformation, and aggregation.</p>
                <div class="alert alert-info">
                    <strong>Main Class:</strong> <code>DataLakeETLPipeline</code> - Orchestrates complete ETL workflow
                </div>
                
                <h3>airflow/dags/spark_etl_dag.py</h3>
                <p>Airflow DAG for automated pipeline orchestration with daily scheduling and error handling.</p>
                <div class="alert alert-info">
                    <strong>DAG ID:</strong> <code>enterprise_etl_pipeline</code> - Runs daily, fully automated
                </div>
                
                <h3>tools/parquet_to_sqlite.py</h3>
                <p>Data export utility for converting Parquet warehouse tables to SQLite format for visualization tools.</p>
                <div class="alert alert-info">
                    <strong>Main Class:</strong> <code>WarehouseDataExporter</code> - Handles format conversion
                </div>
                
                <h3>app.py</h3>
                <p>Superset Flask application factory for analytics platform initialization.</p>
            </section>
            
            <!-- Advanced Configuration -->
            <section>
                <h2>‚öôÔ∏è Advanced Configuration</h2>
                
                <h3>Environment Variables</h3>
                <div class="code-block"><code># Superset Configuration
export SUPERSET_SECRET_KEY='your-secure-key'
export FLASK_APP='superset'

# Spark Configuration
export SPARK_LOCAL_IP='127.0.0.1'
export PYSPARK_PYTHON='/path/to/python'</code></div>
                
                <h3>Airflow Configuration</h3>
                <p>Edit <code>airflow.cfg</code> to customize scheduler, executor, and logging settings. Default configuration uses SequentialExecutor suitable for development.</p>
                
                <div class="alert alert-warning">
                    <strong>Production Note:</strong> Use CeleryExecutor or KubernetesExecutor with Airflow for production deployments
                </div>
            </section>
            
            <!-- Contact Section -->
            <section class="contact-section">
                <h2>ü§ù Support & Contribution</h2>
                <p><strong>Documentation:</strong> Comprehensive guides and API references included in source code</p>
                <p><strong>Issues:</strong> Report bugs and feature requests through project repository</p>
                <p><strong>Contributing:</strong> Pull requests welcome. Follow coding standards and include comprehensive tests</p>
            </section>
        </main>
        
        <footer>
            <p>&copy; 2024 Enterprise Data Lake Platform. Built with Spark, Airflow, and Superset.</p>
            <p style="margin-top: 15px; opacity: 0.8;">Advanced Data Engineering Infrastructure for Modern Organizations</p>
        </footer>
    </div>
</body>
</html>
