
---

# On-Premises Data Lake using Apache Spark, Airflow & Superset

A complete **on-premises data lake and analytics pipeline** built using **Apache Spark for ETL processing**, **Apache Airflow for workflow orchestration**, and **Apache Superset for business intelligence and visualization**.
This project demonstrates the full **Raw â†’ Processed â†’ Warehouse â†’ Analytics** lifecycle for structured enterprise data.

---

##  Project Objective

To design and implement a **local data lake architecture** that:

* Ingests raw transactional data
* Performs scalable ETL using Apache Spark
* Automates workflows using Apache Airflow
* Builds analytical warehouse tables
* Visualizes business insights using Apache Superset

This project is developed as part of the **Data Mining and Warehousing Laboratory**.

---

##  System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Raw Data Layer                       â”‚
â”‚        (sales.csv, customers.csv)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Apache Airflow Orchestration                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ File Check  â”‚â”€â–¶â”‚Spark ETL â”‚â”€â–¶â”‚ Output Validate â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Processed Data Layer                         â”‚
â”‚  sales_clean | customers_clean | sales_with_customers  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Warehouse Analytics Layer                   â”‚
â”‚  revenue_by_product | revenue_by_region                 â”‚
â”‚  payment_analysis | status_summary                      â”‚
â”‚  customer_summary | monthly_sales                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Apache Superset (Analytics Dashboard)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Technology Stack

* **Apache Spark 3.5+** â€“ Distributed ETL processing
* **Apache Airflow 2.6.3** â€“ Workflow orchestration
* **Apache Superset** â€“ Business Intelligence dashboard
* **Python 3.11+** â€“ Core programming language
* **Pandas & PyArrow** â€“ Data handling
* **SQLite** â€“ Analytical warehouse database

---

## ğŸ“ Project Structure

```
onprem-datalake/
â”œâ”€â”€ airflow/dags/
â”‚   â””â”€â”€ spark_etl_dag.py
â”œâ”€â”€ spark/
â”‚   â””â”€â”€ spark_etl.py
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ parquet_to_sqlite.py
â”œâ”€â”€ datalake/
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ warehouse/
â”œâ”€â”€ app.py
â”œâ”€â”€ superset_config.py
â”œâ”€â”€ init_superset.ps1
â”œâ”€â”€ run_superset.ps1
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ”„ ETL Pipeline Description

**Airflow DAG:** `data_lake_etl_pipeline`
**Schedule:** Daily

### Pipeline Tasks:

1. **Check Input Files** â€“ Verifies presence of raw CSV files
2. **Run Spark ETL** â€“ Data cleaning, transformation, and aggregation
3. **Validate Warehouse Output** â€“ Confirms all analytics tables are created
4. **Success Notification**

The Spark ETL also includes a **Pandas fallback mode** to ensure execution even if Spark fails.

---

## ğŸ“Š Warehouse Analytics Tables

| Table Name         | Description                    |
| ------------------ | ------------------------------ |
| revenue_by_product | Product-wise sales and revenue |
| revenue_by_region  | Regional business performance  |
| payment_analysis   | Payment method analysis        |
| status_summary     | Order status distribution      |
| customer_summary   | Customer purchase summary      |
| monthly_sales      | Monthly sales trend            |

---

## âš™ï¸ Setup Instructions (Windows)

### 1ï¸âƒ£ Install Dependencies

```powershell
pip install -r requirements.txt
```

---

### 2ï¸âƒ£ Prepare Input Data

Place the following files in:

```
datalake/raw/
- sales.csv
- customers.csv
```

---

### 3ï¸âƒ£ Initialize Superset

```powershell
.\init_superset.ps1
```

This will:

* Initialize Superset database
* Create default admin user
* Configure roles and permissions

---

### 4ï¸âƒ£ Start Services

#### Option 1: Airflow Standalone

```powershell
airflow standalone
```

#### Option 2: Manual Mode

```powershell
airflow webserver --port 8080
airflow scheduler
```

#### Start Superset

```powershell
.\run_superset.ps1
```

**Access URLs:**

* Airflow: [http://localhost:8080](http://localhost:8080)
* Superset: [http://localhost:8088](http://localhost:8088)
* Login: admin / admin

---

## â–¶ï¸ Trigger ETL Pipeline

```powershell
airflow dags trigger data_lake_etl_pipeline
```

Or from Airflow Web UI.

---

##  Run Spark ETL Manually

```powershell
spark-submit spark/spark_etl.py
```

With memory:

```powershell
spark-submit --driver-memory 4g --executor-memory 4g spark/spark_etl.py
```

---

##  Convert Warehouse Parquet to SQLite

```powershell
python tools/parquet_to_sqlite.py
```

Output:

```
datalake/warehouse.db
```

Used as the Superset data source.

---

## ğŸ–¥ï¸  Complete Final Execution Flow (For Viva & Demo)

### Step 1: Open Project in VS Code

```powershell
cd onprem-datalake
```

### Step 2: Install Dependencies

```powershell
pip install -r requirements.txt
```

### Step 3: Start Airflow

```powershell
airflow standalone
```

### Step 4: Trigger ETL Pipeline

```powershell
airflow dags trigger data_lake_etl_pipeline
```

### Step 5: Verify Output Data

Check:

```
datalake/processed/
datalake/warehouse/
```

### Step 6: Convert to SQLite for Superset

```powershell
python tools/parquet_to_sqlite.py
```

### Step 7: Start Superset

```powershell
.\run_superset.ps1
```

### Step 8: Open Dashboard

```
http://localhost:8088
Login: admin / admin
Dashboards â†’ Sales Analytics Dashboard
```

---

## ğŸ“ˆ Superset Dashboard Visualizations

1. **Revenue by Product** â€“ Area Chart
2. **Revenue by Region** â€“ Pie Chart
3. **Monthly Sales Trend** â€“ Line Chart

These charts provide real-time business intelligence from warehouse data.

---

## â­ Key Features

* Fully automated daily ETL pipeline
* Spark + Pandas fallback system
* Multi-layer on-premise data lake
* Workflow orchestration using Apache Airflow
* Interactive analytics via Apache Superset
* Lightweight SQLite warehouse

---

## âœ… Results & Observations

* End-to-end data pipeline executed successfully
* Airflow DAG runs without failure
* Spark processes raw data accurately
* Analytics tables generated correctly
* Superset dashboards display correct business insights




---

## ğŸ“š References

* Apache Spark Documentation
* Apache Airflow Documentation
* Apache Superset Documentation

---

## ğŸ‘¨â€ğŸ“ Author

**Gaurav Kumar (MSA24002)**
Course: Data Mining and Warehousing Laboratory
Project Type: **On-Premises Data Lake Implementation**

---
